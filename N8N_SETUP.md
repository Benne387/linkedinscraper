# LinkedIn Scraper fÃ¼r n8n - Setup Guide

## ğŸ¯ Wie es funktioniert

### 1ï¸âƒ£ **Erste Nutzung - Session erstellen**
```powershell
python scrape_batch.py https://linkedin.com/in/profile1 https://linkedin.com/in/profile2
```

Das Script wird:
- Browser Ã¶ffnen
- Dich auffordern manuell einzuloggen (inklusive 2FA)
- Session/Cookies in `linkedin_session/cookies.json` speichern
- Profile scrapen und in `scraped_data/` speichern

### 2ï¸âƒ£ **n8n Integration**

#### Option A: Ãœber CLI (einfacher)
```powershell
python scrape_n8n.py "https://linkedin.com/in/someprofile"
```

**n8n Workflow Setup:**
1. "Execute Command" Node mit:
   ```
   cmd /c python scrape_n8n.py "{{$json.profile_url}}"
   ```
2. Output ist JSON:
   ```json
   {
     "status": "success",
     "name": "John Doe",
     "company": "Tech Corp",
     "job_title": "Software Engineer",
     "location": "Berlin",
     "experiences": [...],
     "educations": [...]
   }
   ```

#### Option B: Ãœber HTTP/Webhook (fÃ¼r Hetzner)
```bash
# Installiere Flask wenn nicht vorhanden
pip install flask

# Starte Server
python scrape_api.py
# LÃ¤uft auf http://localhost:5000/scrape
```

n8n HTTP Request:
```
POST http://deine-hetzner-ip:5000/scrape
Body: {"url": "https://linkedin.com/in/profile"}
```

---

## ğŸ”‘ Wichtig: Login & 2FA

### Erste Session erstellen (einmalig):
```powershell
python scrape_batch.py https://linkedin.com/in/test
```
â†’ Browser Ã¶ffnet sich â†’ **Du loggst mich manuell ein** â†’ Script speichert Session

### Weitere Scrapes (automatisch):
```powershell
python scrape_n8n.py https://linkedin.com/in/profile1
python scrape_n8n.py https://linkedin.com/in/profile2
python scrape_n8n.py https://linkedin.com/in/profile3
```
â†’ Alle verwenden die **gleiche gespeicherte Session** â†’ **Kein Login nÃ¶tig!**

---

## ğŸ“ Dateistruktur

```
linkedinscraper/
â”œâ”€â”€ scrape_batch.py          â† Mehrere URLs auf einmal (CLI)
â”œâ”€â”€ scrape_n8n.py            â† Einzelne URL fÃ¼r n8n (CLI)
â”œâ”€â”€ scrape_api.py            â† HTTP API fÃ¼r Webhooks (optional)
â”œâ”€â”€ linkedin_session/
â”‚   â””â”€â”€ cookies.json         â† Gespeicherte Session (AUTO)
â””â”€â”€ scraped_data/
    â”œâ”€â”€ John_Doe_20251221_195341.json
    â”œâ”€â”€ Jane_Smith_20251221_195342.json
    â””â”€â”€ ...
```

---

## ğŸš€ n8n Workflow Beispiel

### Einfache Batch-Verarbeitung:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Start - URL Liste          â”‚
â”‚  (z.B. aus CSV oder DB)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  For Each URL  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Execute Command:       â”‚
       â”‚  python scrape_n8n.py   â”‚
       â”‚  "{{$json.url}}"        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Parse JSON Output     â”‚
       â”‚  (name, company, etc)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Speichern in DB       â”‚
       â”‚  oder Export zu CSV    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Wichtige Hinweise

### Session-Ablauf
- Sessions halten ~30 Tage
- Wenn Session ablÃ¤uft: Erneut `scrape_batch.py` mit einer URL ausfÃ¼hren â†’ neu einloggen
- Session wird automatisch erneuert

### LinkedIn Limits
- âš ï¸ LinkedIn blockiert aggressive Scraper
- **Empfehlung:** 1-2 Sekunden Pause zwischen Profilen
- Verwende **Delays** in n8n: `Wait` Node mit 2-3 Sekunden

### Fehlerbehandlung
```json
{
  "status": "error",
  "error": "SESSION_EXPIRED - Bitte erneut manuell einloggen",
  "url": "https://linkedin.com/in/profile"
}
```

---

## ğŸ”„ Workflow-Beispiele

### CSV mit URLs durchgehen:
```
URL
https://linkedin.com/in/profile1
https://linkedin.com/in/profile2
https://linkedin.com/in/profile3
```

n8n:
1. Read CSV
2. For Each Row
3. Execute Command: `python scrape_n8n.py "{{$json.URL}}"`
4. Write to CSV/DB

### Mit Hetzner Automation:
```
Hetzner Console â†’ Cloud Init Script
```

---

## ğŸ› Troubleshooting

### "NO_SESSION - FÃ¼hre scrape_batch.py aus"
â†’ Erste Nutzung? FÃ¼hre `python scrape_batch.py <url>` aus und melde dich an

### "SESSION_EXPIRED"
â†’ Session ist Ã¤lter als 30 Tage. Wiederhole `scrape_batch.py` zum neu einloggen

### Browser Ã¶ffnet nicht
â†’ PrÃ¼fe ob Chrome installiert ist: `chrome --version`

### Selenium Timeout
â†’ LinkedIn ist langsam. ErhÃ¶he Waits in scrape_n8n.py

---

## ğŸ“ Support

Fehlermeldung mit:
```powershell
python scrape_batch.py <url> 2>&1 | Out-File debug.log
```

---

**Viel Erfolg mit n8n! ğŸš€**
